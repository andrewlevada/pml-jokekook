{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Here the idea is to map jokes in the dataset to the (topic, joke) pairs.\n",
    "Also we clean out the worst jokes to increase quality of data a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231657, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[me narrating a documentary about narrators] \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Telling my daughter garlic is good for you. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I've been going through a really rough period ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If I could have dinner with anyone, dead or al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Two guys walk into a bar. The third guy ducks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Joke\n",
       "0   1  [me narrating a documentary about narrators] \"...\n",
       "1   2  Telling my daughter garlic is good for you. Go...\n",
       "2   3  I've been going through a really rough period ...\n",
       "3   4  If I could have dinner with anyone, dead or al...\n",
       "4   5     Two guys walk into a bar. The third guy ducks."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'raw/shortjokes.csv'\n",
    "jokes_df = pd.read_csv(file_path, sep=',', header=0)\n",
    "print(jokes_df.shape)\n",
    "jokes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make header names lowercase\n",
    "jokes_df.columns = jokes_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American culture filtered out: 8360\n",
      "Links filtered out: 614\n",
      "Dark jokes filtered out: 1285\n",
      "Reddit jokes filtered out: 2394\n"
     ]
    }
   ],
   "source": [
    "# American culture (then are not relevant to the global audience)\n",
    "american_culture = ['Trump', 'Biden', 'Ted Cruz', 'Clinton', 'US', 'Republican', \"Democrat\", \"government\", \"Hillary\", \"Tupac\", \"America\", \"Obama\", \"Thanksgiving\", \"Stevie Wonder\"]\n",
    "print(f\"American culture filtered out: {jokes_df['joke'].str.count('|'.join(american_culture)).sum()}\")\n",
    "jokes_df = jokes_df[~jokes_df['joke'].str.contains('|'.join(american_culture))]\n",
    "\n",
    "# Links to images/videos\n",
    "print(f\"Links filtered out: {jokes_df['joke'].str.contains('http').sum()}\")\n",
    "jokes_df = jokes_df[~jokes_df['joke'].str.contains('http')]\n",
    "\n",
    "# Very dark jokes (out editorial decision)\n",
    "dark_jokes = ['rape', 'suicide']\n",
    "print(f\"Dark jokes filtered out: {jokes_df['joke'].str.count('|'.join(dark_jokes)).sum()}\")\n",
    "jokes_df = jokes_df[~jokes_df['joke'].str.contains('|'.join(dark_jokes))]\n",
    "\n",
    "# Reddit-related jokes (not funny - out editorial decision)\n",
    "reddit_jokes = ['Reddit', 'r/', \"reddit\"]\n",
    "print(f\"Reddit jokes filtered out: {jokes_df['joke'].str.count('|'.join(reddit_jokes)).sum()}\")\n",
    "jokes_df = jokes_df[~jokes_df['joke'].str.contains('|'.join(reddit_jokes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing \";\" symbols from jokes\n",
    "jokes_df['joke'] = jokes_df['joke'].str.replace(';', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1;documentary;0\n",
      "2;parenting;1\n",
      "3;work;1\n",
      "4;dinner;0\n",
      "5;bar;0\n",
      "6;Barbie;0\n",
      "7;music;0\n",
      "8;lottery;0\n",
      "9;dating;1\n",
      "10;chivalry;0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from together import Together\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = Together(api_key=os.environ.get('TOGETHER_API_KEY'))\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"You are a system preprocessing dataset of jokes in batches. You are given a batch of jokes.\n",
    "    For each given joke:\n",
    "    1. Extract its topic (that would fit a form \\\"a joke about <topic>\\\"). Prefer a single word to describe the topic.\n",
    "    2. Classify the joke as containing the 'qhtryeihsdpl' tag. The joke contains 'qhtryeihsdpl' if it contains ingrained prejudice against women, or implies men being superior to women or, describes women in a purely sexual objective way. Notice that not all jokes that mention women are 'qhtryeihsdpl'.\n",
    "    \n",
    "    Output only the csv with 3 columns:\n",
    "    <number>;<joke-topic>;<1 if qhtryeihsdpl, 0 otherwise>\n",
    "    ...\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "system_prompt[\"content\"] = system_prompt[\"content\"].replace(\"\\t\", \"\")\n",
    "\n",
    "def process_batch(batch):\n",
    "    content = \"\\n\".join([f\"{i+1};{joke}\" for i, joke in enumerate(batch)])\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=256,\n",
    "        temperature=0.4,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\",\"<|eom_id|>\"],\n",
    "        truncate=32256,\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    # print(content)\n",
    "    # print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(process_batch(jokes_df.head(10)['joke'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 221097\n",
      "So 58 groups are available\n"
     ]
    }
   ],
   "source": [
    "# Running the processing in groups of batches\n",
    "\n",
    "batch_size = 15 # of jokes\n",
    "group_size = 250 # of batches\n",
    "\n",
    "print(f\"Dataset size: {jokes_df.shape[0]}\")\n",
    "print(f\"So {jokes_df.shape[0] // (batch_size * group_size)} groups are available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing group 5 from joke 18750 to joke 22499:\n",
      "Processed batch 1 / 250\n",
      "Processed batch 2 / 250\n",
      "Processed batch 3 / 250\n",
      "Processed batch 4 / 250\n",
      "Processed batch 5 / 250\n",
      "Processed batch 6 / 250\n",
      "Processed batch 7 / 250\n",
      "Processed batch 8 / 250\n",
      "Processed batch 9 / 250\n",
      "Processed batch 10 / 250\n",
      "Processed batch 11 / 250\n",
      "Processed batch 12 / 250\n",
      "Processed batch 13 / 250\n",
      "Processed batch 14 / 250\n",
      "Processed batch 15 / 250\n",
      "Processed batch 16 / 250\n",
      "Processed batch 17 / 250\n",
      "Processed batch 18 / 250\n",
      "Processed batch 19 / 250\n",
      "Processed batch 20 / 250\n",
      "Processed batch 21 / 250\n",
      "Processed batch 22 / 250\n",
      "Processed batch 23 / 250\n",
      "Processed batch 24 / 250\n",
      "Processed batch 25 / 250\n",
      "Processed batch 26 / 250\n",
      "Processed batch 27 / 250\n",
      "Processed batch 28 / 250\n",
      "Processed batch 29 / 250\n",
      "Processed batch 30 / 250\n",
      "Processed batch 31 / 250\n",
      "Processed batch 32 / 250\n",
      "Processed batch 33 / 250\n",
      "Processed batch 34 / 250\n",
      "Processed batch 35 / 250\n",
      "Processed batch 36 / 250\n",
      "Processed batch 37 / 250\n",
      "Processed batch 38 / 250\n",
      "Processed batch 39 / 250\n",
      "Processed batch 40 / 250\n",
      "Processed batch 41 / 250\n",
      "Processed batch 42 / 250\n",
      "Processed batch 43 / 250\n",
      "Processed batch 44 / 250\n",
      "Processed batch 45 / 250\n",
      "Processed batch 46 / 250\n",
      "Processed batch 47 / 250\n",
      "Processed batch 48 / 250\n",
      "Processed batch 49 / 250\n",
      "Processed batch 50 / 250\n",
      "Processed batch 51 / 250\n",
      "Processed batch 52 / 250\n",
      "Processed batch 53 / 250\n",
      "Processed batch 54 / 250\n",
      "Processed batch 55 / 250\n",
      "Processed batch 56 / 250\n",
      "Processed batch 57 / 250\n",
      "Processed batch 58 / 250\n",
      "Processed batch 59 / 250\n",
      "Processed batch 60 / 250\n",
      "Processed batch 61 / 250\n",
      "Processed batch 62 / 250\n",
      "Processed batch 63 / 250\n",
      "Processed batch 64 / 250\n",
      "Processed batch 65 / 250\n",
      "Processed batch 66 / 250\n",
      "Processed batch 67 / 250\n",
      "Processed batch 68 / 250\n",
      "Processed batch 69 / 250\n",
      "Processed batch 70 / 250\n",
      "Processed batch 71 / 250\n",
      "Processed batch 72 / 250\n",
      "Processed batch 73 / 250\n",
      "Processed batch 74 / 250\n",
      "Processed batch 75 / 250\n",
      "Processed batch 76 / 250\n",
      "Processed batch 77 / 250\n",
      "Processed batch 78 / 250\n",
      "Processed batch 79 / 250\n",
      "Processed batch 80 / 250\n",
      "Processed batch 81 / 250\n",
      "Processed batch 82 / 250\n",
      "Processed batch 83 / 250\n",
      "Processed batch 84 / 250\n",
      "Processed batch 85 / 250\n",
      "Processed batch 86 / 250\n",
      "Processed batch 87 / 250\n",
      "Processed batch 88 / 250\n",
      "Processed batch 89 / 250\n",
      "Processed batch 90 / 250\n",
      "Processed batch 91 / 250\n",
      "Processed batch 92 / 250\n",
      "Processed batch 93 / 250\n",
      "Processed batch 94 / 250\n",
      "Processed batch 95 / 250\n",
      "Processed batch 96 / 250\n",
      "Processed batch 97 / 250\n",
      "Processed batch 98 / 250\n",
      "Processed batch 99 / 250\n",
      "Processed batch 100 / 250\n",
      "Processed batch 101 / 250\n",
      "Processed batch 102 / 250\n",
      "Processed batch 103 / 250\n",
      "Processed batch 104 / 250\n",
      "Processed batch 105 / 250\n",
      "Processed batch 106 / 250\n",
      "Processed batch 107 / 250\n",
      "Processed batch 108 / 250\n",
      "Processed batch 109 / 250\n",
      "Processed batch 110 / 250\n",
      "Processed batch 111 / 250\n",
      "Processed batch 112 / 250\n",
      "Processed batch 113 / 250\n",
      "Processed batch 114 / 250\n",
      "Processed batch 115 / 250\n",
      "Processed batch 116 / 250\n",
      "Processed batch 117 / 250\n",
      "Processed batch 118 / 250\n",
      "Processed batch 119 / 250\n",
      "Processed batch 120 / 250\n",
      "Processed batch 121 / 250\n",
      "Processed batch 122 / 250\n",
      "Processed batch 123 / 250\n",
      "Processed batch 124 / 250\n",
      "Processed batch 125 / 250\n",
      "Processed batch 126 / 250\n",
      "Processed batch 127 / 250\n",
      "Processed batch 128 / 250\n",
      "Processed batch 129 / 250\n",
      "Processed batch 130 / 250\n",
      "Processed batch 131 / 250\n",
      "Processed batch 132 / 250\n",
      "Processed batch 133 / 250\n",
      "Processed batch 134 / 250\n",
      "Processed batch 135 / 250\n",
      "Processed batch 136 / 250\n",
      "Processed batch 137 / 250\n",
      "Processed batch 138 / 250\n",
      "Processed batch 139 / 250\n",
      "Processed batch 140 / 250\n",
      "Processed batch 141 / 250\n",
      "Processed batch 142 / 250\n",
      "Processed batch 143 / 250\n",
      "Processed batch 144 / 250\n",
      "Processed batch 145 / 250\n",
      "Processed batch 146 / 250\n",
      "Processed batch 147 / 250\n",
      "Processed batch 148 / 250\n",
      "Processed batch 149 / 250\n",
      "Processed batch 150 / 250\n",
      "Processed batch 151 / 250\n",
      "Processed batch 152 / 250\n",
      "Processed batch 153 / 250\n",
      "Processed batch 154 / 250\n",
      "Processed batch 155 / 250\n",
      "Processed batch 156 / 250\n",
      "Processed batch 157 / 250\n",
      "Processed batch 158 / 250\n",
      "Processed batch 159 / 250\n",
      "Processed batch 160 / 250\n",
      "Processed batch 161 / 250\n",
      "Processed batch 162 / 250\n",
      "Processed batch 163 / 250\n",
      "Processed batch 164 / 250\n",
      "Processed batch 165 / 250\n",
      "Processed batch 166 / 250\n",
      "Processed batch 167 / 250\n",
      "Processed batch 168 / 250\n",
      "Processed batch 169 / 250\n",
      "Processed batch 170 / 250\n",
      "Processed batch 171 / 250\n",
      "Processed batch 172 / 250\n",
      "Processed batch 173 / 250\n",
      "Processed batch 174 / 250\n",
      "Processed batch 175 / 250\n",
      "Processed batch 176 / 250\n",
      "Processed batch 177 / 250\n",
      "Processed batch 178 / 250\n",
      "Processed batch 179 / 250\n",
      "Processed batch 180 / 250\n",
      "Processed batch 181 / 250\n",
      "Processed batch 182 / 250\n",
      "Processed batch 183 / 250\n",
      "Processed batch 184 / 250\n",
      "Processed batch 185 / 250\n",
      "Processed batch 186 / 250\n",
      "Processed batch 187 / 250\n",
      "Processed batch 188 / 250\n",
      "Processed batch 189 / 250\n",
      "Processed batch 190 / 250\n",
      "Processed batch 191 / 250\n",
      "Processed batch 192 / 250\n",
      "Processed batch 193 / 250\n",
      "Processed batch 194 / 250\n",
      "Processed batch 195 / 250\n",
      "Processed batch 196 / 250\n",
      "Processed batch 197 / 250\n",
      "Processed batch 198 / 250\n",
      "Processed batch 199 / 250\n",
      "Processed batch 200 / 250\n",
      "Processed batch 201 / 250\n",
      "Processed batch 202 / 250\n",
      "Processed batch 203 / 250\n",
      "Processed batch 204 / 250\n",
      "Processed batch 205 / 250\n",
      "Processed batch 206 / 250\n",
      "Processed batch 207 / 250\n",
      "Processed batch 208 / 250\n",
      "Processed batch 209 / 250\n",
      "Processed batch 210 / 250\n",
      "Processed batch 211 / 250\n",
      "Processed batch 212 / 250\n",
      "Processed batch 213 / 250\n",
      "Processed batch 214 / 250\n",
      "Processed batch 215 / 250\n",
      "Processed batch 216 / 250\n",
      "Processed batch 217 / 250\n",
      "Processed batch 218 / 250\n",
      "Processed batch 219 / 250\n",
      "Processed batch 220 / 250\n",
      "Processed batch 221 / 250\n",
      "Processed batch 222 / 250\n",
      "Processed batch 223 / 250\n",
      "Processed batch 224 / 250\n",
      "Processed batch 225 / 250\n",
      "Processed batch 226 / 250\n",
      "Processed batch 227 / 250\n",
      "Processed batch 228 / 250\n",
      "Processed batch 229 / 250\n",
      "Processed batch 230 / 250\n",
      "Processed batch 231 / 250\n",
      "Processed batch 232 / 250\n",
      "Processed batch 233 / 250\n",
      "Processed batch 234 / 250\n",
      "Processed batch 235 / 250\n",
      "Processed batch 236 / 250\n",
      "Processed batch 237 / 250\n",
      "Processed batch 238 / 250\n",
      "Processed batch 239 / 250\n",
      "Processed batch 240 / 250\n",
      "Processed batch 241 / 250\n",
      "Processed batch 242 / 250\n",
      "Processed batch 243 / 250\n",
      "Processed batch 244 / 250\n",
      "Processed batch 245 / 250\n",
      "Processed batch 246 / 250\n",
      "Processed batch 247 / 250\n",
      "Processed batch 248 / 250\n",
      "Processed batch 249 / 250\n",
      "Processed batch 250 / 250\n",
      "Finished processing group 5\n",
      "\n",
      "Processing group 6 from joke 22500 to joke 26249:\n",
      "Processed batch 1 / 250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(from_index, to_index, batch_size):\n\u001b[0;32m     24\u001b[0m     batch \u001b[38;5;241m=\u001b[39m jokes_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoke\u001b[39m\u001b[38;5;124m'\u001b[39m][batch_start:\u001b[38;5;28mmin\u001b[39m(batch_start\u001b[38;5;241m+\u001b[39mbatch_size, to_index)]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 26\u001b[0m     processed_batch \u001b[38;5;241m=\u001b[39m process_batch(batch)\n\u001b[0;32m     27\u001b[0m     processed_batch \u001b[38;5;241m=\u001b[39m processed_batch\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m     processed_batch \u001b[38;5;241m=\u001b[39m [line \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m processed_batch \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()]\n",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m, in \u001b[0;36mprocess_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_batch\u001b[39m(batch):\n\u001b[0;32m     24\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoke\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, joke \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch)])\n\u001b[1;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     27\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     29\u001b[0m             system_prompt,\n\u001b[0;32m     30\u001b[0m             {\n\u001b[0;32m     31\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content,\n\u001b[0;32m     33\u001b[0m             }\n\u001b[0;32m     34\u001b[0m         ],\n\u001b[0;32m     35\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m     36\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,\n\u001b[0;32m     37\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     38\u001b[0m         top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     39\u001b[0m         repetition_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     40\u001b[0m         stop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eom_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     41\u001b[0m         truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32256\u001b[39m,\n\u001b[0;32m     42\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# print(content)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# print(response.choices[0].message.content)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32md:\\ProgramFiles\\miniconda3\\Lib\\site-packages\\together\\resources\\chat\\completions.py:141\u001b[0m, in \u001b[0;36mChatCompletions.create\u001b[1;34m(self, messages, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, presence_penalty, frequency_penalty, min_p, logit_bias, seed, stream, logprobs, echo, n, safety_model, response_format, tools, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m requestor \u001b[38;5;241m=\u001b[39m api_requestor\u001b[38;5;241m.\u001b[39mAPIRequestor(\n\u001b[0;32m    113\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    114\u001b[0m )\n\u001b[0;32m    116\u001b[0m parameter_payload \u001b[38;5;241m=\u001b[39m ChatCompletionRequest(\n\u001b[0;32m    117\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    118\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    139\u001b[0m )\u001b[38;5;241m.\u001b[39mmodel_dump(exclude_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 141\u001b[0m response, _, _ \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    142\u001b[0m     options\u001b[38;5;241m=\u001b[39mTogetherRequest(\n\u001b[0;32m    143\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    144\u001b[0m         url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    145\u001b[0m         params\u001b[38;5;241m=\u001b[39mparameter_payload,\n\u001b[0;32m    146\u001b[0m     ),\n\u001b[0;32m    147\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    148\u001b[0m )\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, TogetherResponse)\n",
      "File \u001b[1;32md:\\ProgramFiles\\miniconda3\\Lib\\site-packages\\together\\abstract\\api_requestor.py:242\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, options, stream, remaining_retries, request_timeout)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    233\u001b[0m     options: TogetherRequest,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    241\u001b[0m ]:\n\u001b[1;32m--> 242\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    243\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    244\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries,\n\u001b[0;32m    245\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    246\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    247\u001b[0m     )\n\u001b[0;32m    249\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32md:\\ProgramFiles\\miniconda3\\Lib\\site-packages\\together\\abstract\\api_requestor.py:545\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, options, remaining_retries, stream, request_timeout, absolute)\u001b[0m\n\u001b[0;32m    542\u001b[0m         result_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(result\u001b[38;5;241m.\u001b[39mheaders) \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 545\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    546\u001b[0m                 options,\n\u001b[0;32m    547\u001b[0m                 remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    548\u001b[0m                 response_headers\u001b[38;5;241m=\u001b[39mresult_headers,\n\u001b[0;32m    549\u001b[0m                 stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    550\u001b[0m                 request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    551\u001b[0m             )\n\u001b[0;32m    553\u001b[0m status_code \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    554\u001b[0m result_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(result\u001b[38;5;241m.\u001b[39mheaders) \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "File \u001b[1;32md:\\ProgramFiles\\miniconda3\\Lib\\site-packages\\together\\abstract\\api_requestor.py:192\u001b[0m, in \u001b[0;36mAPIRequestor._retry_request\u001b[1;34m(self, options, remaining_retries, response_headers, stream, request_timeout)\u001b[0m\n\u001b[0;32m    188\u001b[0m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    195\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    196\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    197\u001b[0m     request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    198\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m    199\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target_groups = range(5, 8) # for out-of-order processing\n",
    "\n",
    "output_folder = 'processed'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for group in target_groups:\n",
    "    output_file = os.path.join(output_folder, f\"processed_{group}.csv\")\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Skipping group {group} because the file already exists\")\n",
    "        continue\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        f.write('\"Joke\";\"Joke topic\"\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    from_index = group * group_size * batch_size\n",
    "    to_index = min(from_index + group_size * batch_size, jokes_df.shape[0])\n",
    "    \n",
    "    print(f\"Processing group {group} from joke {from_index} to joke {to_index - 1}:\")\n",
    "\n",
    "    for batch_start in range(from_index, to_index, batch_size):\n",
    "        batch = jokes_df['joke'][batch_start:min(batch_start+batch_size, to_index)].tolist()\n",
    "\n",
    "        processed_batch = process_batch(batch)\n",
    "        processed_batch = processed_batch.split('\\n')\n",
    "        processed_batch = [line for line in processed_batch if line.strip()]\n",
    "        processed_batch = processed_batch[:len(batch)]\n",
    "\n",
    "        jokes_to_write = []\n",
    "\n",
    "        for joke_id, joke in enumerate(processed_batch):\n",
    "            cols = joke.split(';')\n",
    "\n",
    "            # error validation\n",
    "            if len(cols) != 3: continue\n",
    "\n",
    "            # skipping flagged jokes\n",
    "            if cols[-1].strip() != '0': continue\n",
    "\n",
    "            jokes_to_write.append((batch[joke_id], cols[1]))\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            for joke, topic in jokes_to_write:\n",
    "                f.write(f\"{joke};{topic}\\n\")\n",
    "        \n",
    "        print(f\"Processed batch {batch_count + 1} / {group_size}\")\n",
    "        batch_count += 1\n",
    "\n",
    "    print(f\"Finished processing group {group}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Now stitching all processed files into one\n",
    "processed_files = glob.glob(os.path.join(output_folder, 'processed_*.csv'))\n",
    "processed_files.sort()\n",
    "\n",
    "# Stitching all files into one\n",
    "with open('processed/all_processed.csv', 'w') as f:\n",
    "    f.write('\"Joke\";\"Joke topic\"\\n')\n",
    "    \n",
    "    for file in processed_files:\n",
    "        with open(file, 'r') as infile:\n",
    "            infile.readline()  # Skip the header line\n",
    "            f.write(infile.read())\n",
    "            \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
