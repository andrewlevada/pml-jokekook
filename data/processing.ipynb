{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Here the idea is to map jokes in the dataset to the (topic, joke) pairs.\n",
    "Also we clean out the worst jokes to increase quality of data a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231657, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[me narrating a documentary about narrators] \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Telling my daughter garlic is good for you. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I've been going through a really rough period ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If I could have dinner with anyone, dead or al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Two guys walk into a bar. The third guy ducks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Joke\n",
       "0   1  [me narrating a documentary about narrators] \"...\n",
       "1   2  Telling my daughter garlic is good for you. Go...\n",
       "2   3  I've been going through a really rough period ...\n",
       "3   4  If I could have dinner with anyone, dead or al...\n",
       "4   5     Two guys walk into a bar. The third guy ducks."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'raw/shortjokes.csv'\n",
    "jokes_df = pd.read_csv(file_path, sep=',', header=0)\n",
    "print(jokes_df.shape)\n",
    "jokes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make header names lowercase\n",
    "jokes_df.columns = jokes_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American culture filtered out: 8360\n",
      "Links filtered out: 614\n",
      "Dark jokes filtered out: 1285\n",
      "Reddit jokes filtered out: 2394\n"
     ]
    }
   ],
   "source": [
    "# American culture (then are not relevant to the global audience)\n",
    "american_culture = ['Trump', 'Biden', 'Ted Cruz', 'Clinton', 'US', 'Republican', \"Democrat\", \"government\", \"Hillary\", \"Tupac\", \"America\", \"Obama\", \"Thanksgiving\", \"Stevie Wonder\"]\n",
    "print(f\"American culture filtered out: {jokes_df['joke'].str.count('|'.join(american_culture)).sum()}\")\n",
    "jokes_df = jokes_df[~jokes_df['joke'].str.contains('|'.join(american_culture))]\n",
    "\n",
    "# Links to images/videos\n",
    "print(f\"Links filtered out: {jokes_df['joke'].str.contains('http').sum()}\")\n",
    "jokes_df = jokes_df[~jokes_df['joke'].str.contains('http')]\n",
    "\n",
    "# Very dark jokes (out editorial decision)\n",
    "dark_jokes = ['rape', 'suicide']\n",
    "print(f\"Dark jokes filtered out: {jokes_df['joke'].str.count('|'.join(dark_jokes)).sum()}\")\n",
    "jokes_df = jokes_df[~jokes_df['joke'].str.contains('|'.join(dark_jokes))]\n",
    "\n",
    "# Reddit-related jokes (not funny - out editorial decision)\n",
    "reddit_jokes = ['Reddit', 'r/', \"reddit\"]\n",
    "print(f\"Reddit jokes filtered out: {jokes_df['joke'].str.count('|'.join(reddit_jokes)).sum()}\")\n",
    "jokes_df = jokes_df[~jokes_df['joke'].str.contains('|'.join(reddit_jokes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing \";\" symbols from jokes\n",
    "jokes_df['joke'] = jokes_df['joke'].str.replace(';', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1;documentary;0\n",
      "2;parenting;1\n",
      "3;work;1\n",
      "4;dinner;0\n",
      "5;bar;0\n",
      "6;Barbie;1\n",
      "7;music;0\n",
      "8;lottery;0\n",
      "9;dating;1\n",
      "10;gentleman;1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from together import Together\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = Together(api_key=os.environ.get('TOGETHER_API_KEY'))\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"You are a system preprocessing dataset of jokes in batches. You are given a batch of jokes.\n",
    "    For each given joke:\n",
    "    1. Extract its topic (that would fit a form \\\"a joke about <topic>\\\"). Prefer a single word to describe the topic.\n",
    "    2. Classify the joke as containing the 'qhtryeihsdpl' tag. The joke contains 'qhtryeihsdpl' if it contains ingrained prejudice against women, or implies men being superior to women or, describes women in a purely sexual objective way. Notice that not all jokes that mention women are 'qhtryeihsdpl'.\n",
    "    \n",
    "    Output only the csv with 3 columns:\n",
    "    <number>;<joke-topic>;<1 if qhtryeihsdpl, 0 otherwise>\n",
    "    ...\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "system_prompt[\"content\"] = system_prompt[\"content\"].replace(\"\\t\", \"\")\n",
    "\n",
    "def process_batch(batch):\n",
    "    content = \"\\n\".join([f\"{i+1};{joke}\" for i, joke in enumerate(batch)])\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=256,\n",
    "        temperature=0.4,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\",\"<|eom_id|>\"],\n",
    "        truncate=32256,\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    # print(content)\n",
    "    # print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(process_batch(jokes_df.head(10)['joke'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 221097\n",
      "So 58 groups are available\n"
     ]
    }
   ],
   "source": [
    "# Running the processing in groups of batches\n",
    "\n",
    "batch_size = 15 # of jokes\n",
    "group_size = 250 # of batches\n",
    "\n",
    "print(f\"Dataset size: {jokes_df.shape[0]}\")\n",
    "print(f\"So {jokes_df.shape[0] // (batch_size * group_size)} groups are available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing group 16 from joke 60000 to joke 63749:\n",
      "Processed batch 1 / 250\n",
      "Processed batch 2 / 250\n",
      "Processed batch 3 / 250\n",
      "Processed batch 4 / 250\n",
      "Processed batch 5 / 250\n",
      "Processed batch 6 / 250\n",
      "Processed batch 7 / 250\n",
      "Processed batch 8 / 250\n",
      "Processed batch 9 / 250\n",
      "Processed batch 10 / 250\n",
      "Processed batch 11 / 250\n",
      "Processed batch 12 / 250\n",
      "Processed batch 13 / 250\n",
      "Processed batch 14 / 250\n",
      "Processed batch 15 / 250\n",
      "Processed batch 16 / 250\n",
      "Processed batch 17 / 250\n",
      "Processed batch 18 / 250\n",
      "Processed batch 19 / 250\n",
      "Processed batch 20 / 250\n",
      "Processed batch 21 / 250\n",
      "Processed batch 22 / 250\n",
      "Processed batch 23 / 250\n",
      "Processed batch 24 / 250\n",
      "Processed batch 25 / 250\n",
      "Processed batch 26 / 250\n",
      "Processed batch 27 / 250\n",
      "Processed batch 28 / 250\n",
      "Processed batch 29 / 250\n",
      "Processed batch 30 / 250\n",
      "Processed batch 31 / 250\n",
      "Processed batch 32 / 250\n",
      "Processed batch 33 / 250\n",
      "Processed batch 34 / 250\n",
      "Processed batch 35 / 250\n",
      "Processed batch 36 / 250\n",
      "Processed batch 37 / 250\n",
      "Processed batch 38 / 250\n",
      "Processed batch 39 / 250\n",
      "Processed batch 40 / 250\n",
      "Processed batch 41 / 250\n",
      "Processed batch 42 / 250\n",
      "Processed batch 43 / 250\n",
      "Processed batch 44 / 250\n",
      "Processed batch 45 / 250\n",
      "Processed batch 46 / 250\n",
      "Processed batch 47 / 250\n",
      "Processed batch 48 / 250\n",
      "Processed batch 49 / 250\n",
      "Processed batch 50 / 250\n",
      "Processed batch 51 / 250\n",
      "Processed batch 52 / 250\n",
      "Processed batch 53 / 250\n",
      "Processed batch 54 / 250\n",
      "Processed batch 55 / 250\n",
      "Processed batch 56 / 250\n",
      "Processed batch 57 / 250\n",
      "Processed batch 58 / 250\n",
      "Processed batch 59 / 250\n",
      "Processed batch 60 / 250\n",
      "Processed batch 61 / 250\n",
      "Processed batch 62 / 250\n",
      "Processed batch 63 / 250\n",
      "Processed batch 64 / 250\n",
      "Processed batch 65 / 250\n",
      "Processed batch 66 / 250\n",
      "Processed batch 67 / 250\n",
      "Processed batch 68 / 250\n",
      "Processed batch 69 / 250\n",
      "Processed batch 70 / 250\n",
      "Processed batch 71 / 250\n",
      "Processed batch 72 / 250\n",
      "Processed batch 73 / 250\n",
      "Processed batch 74 / 250\n",
      "Processed batch 75 / 250\n",
      "Processed batch 76 / 250\n",
      "Processed batch 77 / 250\n",
      "Processed batch 78 / 250\n",
      "Processed batch 79 / 250\n",
      "Processed batch 80 / 250\n",
      "Processed batch 81 / 250\n",
      "Processed batch 82 / 250\n",
      "Processed batch 83 / 250\n",
      "Processed batch 84 / 250\n",
      "Processed batch 85 / 250\n",
      "Processed batch 86 / 250\n",
      "Processed batch 87 / 250\n",
      "Processed batch 88 / 250\n",
      "Processed batch 89 / 250\n",
      "Processed batch 90 / 250\n",
      "Processed batch 91 / 250\n",
      "Processed batch 92 / 250\n",
      "Processed batch 93 / 250\n",
      "Processed batch 94 / 250\n",
      "Processed batch 95 / 250\n",
      "Processed batch 96 / 250\n",
      "Processed batch 97 / 250\n",
      "Processed batch 98 / 250\n",
      "Processed batch 99 / 250\n",
      "Processed batch 100 / 250\n",
      "Processed batch 101 / 250\n",
      "Processed batch 102 / 250\n",
      "Processed batch 103 / 250\n",
      "Processed batch 104 / 250\n",
      "Processed batch 105 / 250\n",
      "Processed batch 106 / 250\n",
      "Processed batch 107 / 250\n",
      "Processed batch 108 / 250\n",
      "Processed batch 109 / 250\n",
      "Processed batch 110 / 250\n",
      "Processed batch 111 / 250\n",
      "Processed batch 112 / 250\n",
      "Processed batch 113 / 250\n",
      "Processed batch 114 / 250\n",
      "Processed batch 115 / 250\n",
      "Processed batch 116 / 250\n",
      "Processed batch 117 / 250\n",
      "Processed batch 118 / 250\n",
      "Processed batch 119 / 250\n",
      "Processed batch 120 / 250\n",
      "Processed batch 121 / 250\n",
      "Processed batch 122 / 250\n",
      "Processed batch 123 / 250\n",
      "Processed batch 124 / 250\n",
      "Processed batch 125 / 250\n",
      "Processed batch 126 / 250\n",
      "Processed batch 127 / 250\n",
      "Processed batch 128 / 250\n",
      "Processed batch 129 / 250\n",
      "Processed batch 130 / 250\n",
      "Processed batch 131 / 250\n",
      "Processed batch 132 / 250\n",
      "Processed batch 133 / 250\n",
      "Processed batch 134 / 250\n",
      "Processed batch 135 / 250\n",
      "Processed batch 136 / 250\n",
      "Processed batch 137 / 250\n",
      "Processed batch 138 / 250\n",
      "Processed batch 139 / 250\n",
      "Processed batch 140 / 250\n",
      "Processed batch 141 / 250\n",
      "Processed batch 142 / 250\n",
      "Processed batch 143 / 250\n",
      "Processed batch 144 / 250\n",
      "Processed batch 145 / 250\n",
      "Processed batch 146 / 250\n",
      "Processed batch 147 / 250\n",
      "Processed batch 148 / 250\n",
      "Processed batch 149 / 250\n",
      "Processed batch 150 / 250\n",
      "Processed batch 151 / 250\n",
      "Processed batch 152 / 250\n",
      "Processed batch 153 / 250\n",
      "Processed batch 154 / 250\n",
      "Processed batch 155 / 250\n",
      "Processed batch 156 / 250\n",
      "Processed batch 157 / 250\n",
      "Processed batch 158 / 250\n",
      "Processed batch 159 / 250\n",
      "Processed batch 160 / 250\n",
      "Processed batch 161 / 250\n",
      "Processed batch 162 / 250\n",
      "Processed batch 163 / 250\n",
      "Processed batch 164 / 250\n",
      "Processed batch 165 / 250\n",
      "Processed batch 166 / 250\n",
      "Processed batch 167 / 250\n",
      "Processed batch 168 / 250\n",
      "Processed batch 169 / 250\n",
      "Processed batch 170 / 250\n",
      "Processed batch 171 / 250\n",
      "Processed batch 172 / 250\n",
      "Processed batch 173 / 250\n",
      "Processed batch 174 / 250\n",
      "Processed batch 175 / 250\n",
      "Processed batch 176 / 250\n",
      "Processed batch 177 / 250\n",
      "Processed batch 178 / 250\n",
      "Processed batch 179 / 250\n",
      "Processed batch 180 / 250\n",
      "Processed batch 181 / 250\n",
      "Processed batch 182 / 250\n",
      "Processed batch 183 / 250\n",
      "Processed batch 184 / 250\n",
      "Processed batch 185 / 250\n",
      "Processed batch 186 / 250\n",
      "Processed batch 187 / 250\n",
      "Processed batch 188 / 250\n",
      "Processed batch 189 / 250\n",
      "Processed batch 190 / 250\n",
      "Processed batch 191 / 250\n",
      "Processed batch 192 / 250\n",
      "Processed batch 193 / 250\n",
      "Processed batch 194 / 250\n",
      "Processed batch 195 / 250\n",
      "Processed batch 196 / 250\n",
      "Processed batch 197 / 250\n",
      "Processed batch 198 / 250\n",
      "Processed batch 199 / 250\n",
      "Processed batch 200 / 250\n",
      "Processed batch 201 / 250\n",
      "Processed batch 202 / 250\n",
      "Processed batch 203 / 250\n",
      "Processed batch 204 / 250\n",
      "Processed batch 205 / 250\n",
      "Processed batch 206 / 250\n",
      "Processed batch 207 / 250\n",
      "Processed batch 208 / 250\n",
      "Processed batch 209 / 250\n",
      "Processed batch 210 / 250\n",
      "Processed batch 211 / 250\n",
      "Processed batch 212 / 250\n",
      "Processed batch 213 / 250\n",
      "Processed batch 214 / 250\n",
      "Processed batch 215 / 250\n",
      "Processed batch 216 / 250\n",
      "Processed batch 217 / 250\n",
      "Processed batch 218 / 250\n",
      "Processed batch 219 / 250\n",
      "Processed batch 220 / 250\n",
      "Processed batch 221 / 250\n",
      "Processed batch 222 / 250\n",
      "Processed batch 223 / 250\n",
      "Processed batch 224 / 250\n",
      "Processed batch 225 / 250\n",
      "Processed batch 226 / 250\n",
      "Processed batch 227 / 250\n",
      "Processed batch 228 / 250\n",
      "Processed batch 229 / 250\n",
      "Processed batch 230 / 250\n",
      "Processed batch 231 / 250\n",
      "Processed batch 232 / 250\n",
      "Processed batch 233 / 250\n",
      "Processed batch 234 / 250\n",
      "Processed batch 235 / 250\n",
      "Processed batch 236 / 250\n",
      "Processed batch 237 / 250\n",
      "Processed batch 238 / 250\n",
      "Processed batch 239 / 250\n",
      "Processed batch 240 / 250\n",
      "Processed batch 241 / 250\n",
      "Processed batch 242 / 250\n",
      "Processed batch 243 / 250\n",
      "Processed batch 244 / 250\n",
      "Processed batch 245 / 250\n",
      "Processed batch 246 / 250\n",
      "Processed batch 247 / 250\n",
      "Processed batch 248 / 250\n",
      "Processed batch 249 / 250\n",
      "Processed batch 250 / 250\n",
      "Finished processing group 16\n",
      "\n",
      "Processing group 17 from joke 63750 to joke 67499:\n",
      "Processed batch 1 / 250\n",
      "Processed batch 2 / 250\n",
      "Processed batch 3 / 250\n",
      "Processed batch 4 / 250\n",
      "Processed batch 5 / 250\n",
      "Processed batch 6 / 250\n",
      "Processed batch 7 / 250\n",
      "Processed batch 8 / 250\n",
      "Processed batch 9 / 250\n",
      "Processed batch 10 / 250\n",
      "Processed batch 11 / 250\n",
      "Processed batch 12 / 250\n",
      "Processed batch 13 / 250\n",
      "Processed batch 14 / 250\n",
      "Processed batch 15 / 250\n",
      "Processed batch 16 / 250\n",
      "Processed batch 17 / 250\n",
      "Processed batch 18 / 250\n",
      "Processed batch 19 / 250\n",
      "Processed batch 20 / 250\n",
      "Processed batch 21 / 250\n",
      "Processed batch 22 / 250\n",
      "Processed batch 23 / 250\n",
      "Processed batch 24 / 250\n",
      "Processed batch 25 / 250\n",
      "Processed batch 26 / 250\n",
      "Processed batch 27 / 250\n",
      "Processed batch 28 / 250\n",
      "Processed batch 29 / 250\n",
      "Processed batch 30 / 250\n",
      "Processed batch 31 / 250\n",
      "Processed batch 32 / 250\n",
      "Processed batch 33 / 250\n",
      "Processed batch 34 / 250\n",
      "Processed batch 35 / 250\n",
      "Processed batch 36 / 250\n",
      "Processed batch 37 / 250\n",
      "Processed batch 38 / 250\n",
      "Processed batch 39 / 250\n",
      "Processed batch 40 / 250\n",
      "Processed batch 41 / 250\n",
      "Processed batch 42 / 250\n",
      "Processed batch 43 / 250\n",
      "Processed batch 44 / 250\n",
      "Processed batch 45 / 250\n",
      "Processed batch 46 / 250\n",
      "Processed batch 47 / 250\n",
      "Processed batch 48 / 250\n",
      "Processed batch 49 / 250\n",
      "Processed batch 50 / 250\n",
      "Processed batch 51 / 250\n",
      "Processed batch 52 / 250\n",
      "Processed batch 53 / 250\n",
      "Processed batch 54 / 250\n",
      "Processed batch 55 / 250\n",
      "Processed batch 56 / 250\n",
      "Processed batch 57 / 250\n",
      "Processed batch 58 / 250\n",
      "Processed batch 59 / 250\n",
      "Processed batch 60 / 250\n",
      "Processed batch 61 / 250\n",
      "Processed batch 62 / 250\n",
      "Processed batch 63 / 250\n",
      "Processed batch 64 / 250\n",
      "Processed batch 65 / 250\n",
      "Processed batch 66 / 250\n",
      "Processed batch 67 / 250\n",
      "Processed batch 68 / 250\n",
      "Processed batch 69 / 250\n",
      "Processed batch 70 / 250\n",
      "Processed batch 71 / 250\n",
      "Processed batch 72 / 250\n",
      "Processed batch 73 / 250\n",
      "Processed batch 74 / 250\n",
      "Processed batch 75 / 250\n",
      "Processed batch 76 / 250\n",
      "Processed batch 77 / 250\n",
      "Processed batch 78 / 250\n",
      "Processed batch 79 / 250\n",
      "Processed batch 80 / 250\n",
      "Processed batch 81 / 250\n",
      "Processed batch 82 / 250\n",
      "Processed batch 83 / 250\n",
      "Processed batch 84 / 250\n",
      "Processed batch 85 / 250\n",
      "Processed batch 86 / 250\n",
      "Processed batch 87 / 250\n",
      "Processed batch 88 / 250\n",
      "Processed batch 89 / 250\n",
      "Processed batch 90 / 250\n",
      "Processed batch 91 / 250\n",
      "Processed batch 92 / 250\n",
      "Processed batch 93 / 250\n",
      "Processed batch 94 / 250\n",
      "Processed batch 95 / 250\n",
      "Processed batch 96 / 250\n",
      "Processed batch 97 / 250\n",
      "Processed batch 98 / 250\n",
      "Processed batch 99 / 250\n",
      "Processed batch 100 / 250\n",
      "Processed batch 101 / 250\n",
      "Processed batch 102 / 250\n",
      "Processed batch 103 / 250\n",
      "Processed batch 104 / 250\n",
      "Processed batch 105 / 250\n",
      "Processed batch 106 / 250\n",
      "Processed batch 107 / 250\n",
      "Processed batch 108 / 250\n",
      "Processed batch 109 / 250\n",
      "Processed batch 110 / 250\n",
      "Processed batch 111 / 250\n",
      "Processed batch 112 / 250\n",
      "Processed batch 113 / 250\n",
      "Processed batch 114 / 250\n",
      "Processed batch 115 / 250\n",
      "Processed batch 116 / 250\n",
      "Processed batch 117 / 250\n",
      "Processed batch 118 / 250\n",
      "Processed batch 119 / 250\n",
      "Processed batch 120 / 250\n",
      "Processed batch 121 / 250\n",
      "Processed batch 122 / 250\n",
      "Processed batch 123 / 250\n",
      "Processed batch 124 / 250\n",
      "Processed batch 125 / 250\n",
      "Processed batch 126 / 250\n",
      "Processed batch 127 / 250\n",
      "Processed batch 128 / 250\n",
      "Processed batch 129 / 250\n",
      "Processed batch 130 / 250\n",
      "Processed batch 131 / 250\n",
      "Processed batch 132 / 250\n",
      "Processed batch 133 / 250\n",
      "Processed batch 134 / 250\n",
      "Processed batch 135 / 250\n",
      "Processed batch 136 / 250\n",
      "Processed batch 137 / 250\n",
      "Processed batch 138 / 250\n",
      "Processed batch 139 / 250\n",
      "Processed batch 140 / 250\n",
      "Processed batch 141 / 250\n",
      "Processed batch 142 / 250\n",
      "Processed batch 143 / 250\n",
      "Processed batch 144 / 250\n",
      "Processed batch 145 / 250\n",
      "Processed batch 146 / 250\n",
      "Processed batch 147 / 250\n",
      "Processed batch 148 / 250\n",
      "Processed batch 149 / 250\n",
      "Processed batch 150 / 250\n",
      "Processed batch 151 / 250\n",
      "Processed batch 152 / 250\n",
      "Processed batch 153 / 250\n",
      "Processed batch 154 / 250\n",
      "Processed batch 155 / 250\n",
      "Processed batch 156 / 250\n",
      "Processed batch 157 / 250\n",
      "Processed batch 158 / 250\n",
      "Processed batch 159 / 250\n",
      "Processed batch 160 / 250\n",
      "Processed batch 161 / 250\n",
      "Processed batch 162 / 250\n",
      "Processed batch 163 / 250\n",
      "Processed batch 164 / 250\n",
      "Processed batch 165 / 250\n",
      "Processed batch 166 / 250\n",
      "Processed batch 167 / 250\n",
      "Processed batch 168 / 250\n",
      "Processed batch 169 / 250\n",
      "Processed batch 170 / 250\n",
      "Processed batch 171 / 250\n",
      "Processed batch 172 / 250\n",
      "Processed batch 173 / 250\n",
      "Processed batch 174 / 250\n",
      "Processed batch 175 / 250\n",
      "Processed batch 176 / 250\n",
      "Processed batch 177 / 250\n",
      "Processed batch 178 / 250\n",
      "Processed batch 179 / 250\n",
      "Processed batch 180 / 250\n",
      "Processed batch 181 / 250\n",
      "Processed batch 182 / 250\n",
      "Processed batch 183 / 250\n",
      "Processed batch 184 / 250\n",
      "Processed batch 185 / 250\n",
      "Processed batch 186 / 250\n",
      "Processed batch 187 / 250\n",
      "Processed batch 188 / 250\n",
      "Processed batch 189 / 250\n",
      "Processed batch 190 / 250\n",
      "Processed batch 191 / 250\n",
      "Processed batch 192 / 250\n",
      "Processed batch 193 / 250\n",
      "Processed batch 194 / 250\n",
      "Processed batch 195 / 250\n",
      "Processed batch 196 / 250\n",
      "Processed batch 197 / 250\n",
      "Processed batch 198 / 250\n",
      "Processed batch 199 / 250\n",
      "Processed batch 200 / 250\n",
      "Processed batch 201 / 250\n",
      "Processed batch 202 / 250\n",
      "Processed batch 203 / 250\n",
      "Processed batch 204 / 250\n",
      "Processed batch 205 / 250\n",
      "Processed batch 206 / 250\n",
      "Processed batch 207 / 250\n",
      "Processed batch 208 / 250\n",
      "Processed batch 209 / 250\n",
      "Processed batch 210 / 250\n",
      "Processed batch 211 / 250\n",
      "Processed batch 212 / 250\n",
      "Processed batch 213 / 250\n",
      "Processed batch 214 / 250\n",
      "Processed batch 215 / 250\n",
      "Processed batch 216 / 250\n",
      "Processed batch 217 / 250\n",
      "Processed batch 218 / 250\n",
      "Processed batch 219 / 250\n",
      "Processed batch 220 / 250\n",
      "Processed batch 221 / 250\n",
      "Processed batch 222 / 250\n",
      "Processed batch 223 / 250\n",
      "Processed batch 224 / 250\n",
      "Processed batch 225 / 250\n",
      "Processed batch 226 / 250\n",
      "Processed batch 227 / 250\n",
      "Processed batch 228 / 250\n",
      "Processed batch 229 / 250\n",
      "Processed batch 230 / 250\n",
      "Processed batch 231 / 250\n",
      "Processed batch 232 / 250\n",
      "Processed batch 233 / 250\n",
      "Processed batch 234 / 250\n",
      "Processed batch 235 / 250\n",
      "Processed batch 236 / 250\n",
      "Processed batch 237 / 250\n",
      "Processed batch 238 / 250\n",
      "Processed batch 239 / 250\n",
      "Processed batch 240 / 250\n",
      "Processed batch 241 / 250\n",
      "Processed batch 242 / 250\n",
      "Processed batch 243 / 250\n",
      "Processed batch 244 / 250\n",
      "Processed batch 245 / 250\n",
      "Processed batch 246 / 250\n",
      "Processed batch 247 / 250\n",
      "Processed batch 248 / 250\n",
      "Processed batch 249 / 250\n",
      "Processed batch 250 / 250\n",
      "Finished processing group 17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_groups = range(16, 18) # for out-of-order processing\n",
    "\n",
    "output_folder = 'processed'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for group in target_groups:\n",
    "    output_file = os.path.join(output_folder, f\"processed_{group}.csv\")\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Skipping group {group} because the file already exists\")\n",
    "        continue\n",
    "\n",
    "    with open(output_file, 'a') as f:\n",
    "        f.write('\"Joke\";\"Joke topic\"\\n')\n",
    "\n",
    "    batch_count = 0\n",
    "    from_index = group * group_size * batch_size\n",
    "    to_index = min(from_index + group_size * batch_size, jokes_df.shape[0])\n",
    "    \n",
    "    print(f\"Processing group {group} from joke {from_index} to joke {to_index - 1}:\")\n",
    "\n",
    "    for batch_start in range(from_index, to_index, batch_size):\n",
    "        batch = jokes_df['joke'][batch_start:min(batch_start+batch_size, to_index)].tolist()\n",
    "\n",
    "        processed_batch = process_batch(batch)\n",
    "        processed_batch = processed_batch.split('\\n')\n",
    "        processed_batch = [line for line in processed_batch if line.strip()]\n",
    "        processed_batch = processed_batch[:len(batch)]\n",
    "\n",
    "        jokes_to_write = []\n",
    "\n",
    "        for joke_id, joke in enumerate(processed_batch):\n",
    "            cols = joke.split(';')\n",
    "\n",
    "            # error validation\n",
    "            if len(cols) != 3: continue\n",
    "\n",
    "            # skipping flagged jokes\n",
    "            if cols[-1].strip() != '0': continue\n",
    "\n",
    "            jokes_to_write.append((batch[joke_id], cols[1]))\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            for joke, topic in jokes_to_write:\n",
    "                f.write(f\"{joke};{topic}\\n\")\n",
    "        \n",
    "        print(f\"Processed batch {batch_count + 1} / {group_size}\")\n",
    "        batch_count += 1\n",
    "\n",
    "    print(f\"Finished processing group {group}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Now stitching all processed files into one\n",
    "processed_files = glob.glob(os.path.join(output_folder, 'processed_*.csv'))\n",
    "processed_files.sort()\n",
    "\n",
    "# Stitching all files into one\n",
    "with open('processed/all_processed.csv', 'w') as f:\n",
    "    f.write('\"Joke\";\"Joke topic\"\\n')\n",
    "    \n",
    "    for file in processed_files:\n",
    "        with open(file, 'r') as infile:\n",
    "            infile.readline()  # Skip the header line\n",
    "            f.write(infile.read())\n",
    "            \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
